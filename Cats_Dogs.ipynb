{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mitaliid/Fine-Tuning/blob/main/Cats_Dogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D85rnQ1V6jW"
      },
      "source": [
        "## Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uc2GYRZzKyzh",
        "outputId": "b9c70fce-f928-41b6-ebca-b0597f0e1578"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-03 02:51:28--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.137.207, 142.250.101.207, 142.251.2.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.137.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M   117MB/s    in 0.6s    \n",
            "\n",
            "2024-12-03 02:51:29 (117 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgEKdtTjV8Sx"
      },
      "source": [
        "## Reading the Data into arrays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mrkhMsWFhBT",
        "outputId": "bdce3e41-e545-46a2-a3ad-3b9d39ac4ee1"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes: ['cats', 'dogs']\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 152MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 0.3384 Acc: 0.8530\n",
            "val Loss: 0.1059 Acc: 0.9710\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 0.2089 Acc: 0.9125\n",
            "val Loss: 0.0819 Acc: 0.9780\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 0.1992 Acc: 0.9170\n",
            "val Loss: 0.0699 Acc: 0.9800\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 0.1828 Acc: 0.9240\n",
            "val Loss: 0.0649 Acc: 0.9800\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.1527 Acc: 0.9440\n",
            "val Loss: 0.0630 Acc: 0.9800\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.1729 Acc: 0.9195\n",
            "val Loss: 0.0568 Acc: 0.9820\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.1563 Acc: 0.9415\n",
            "val Loss: 0.0559 Acc: 0.9800\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.1712 Acc: 0.9265\n",
            "val Loss: 0.0535 Acc: 0.9840\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.1559 Acc: 0.9385\n",
            "val Loss: 0.0522 Acc: 0.9850\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.1637 Acc: 0.9290\n",
            "val Loss: 0.0523 Acc: 0.9830\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.1490 Acc: 0.9400\n",
            "val Loss: 0.0518 Acc: 0.9840\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.1681 Acc: 0.9220\n",
            "val Loss: 0.0525 Acc: 0.9830\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Import Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "# Step 2: Check Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Step 3: Data Preparation\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Define normalization values for pretrained models\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "# Data transformations\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std),\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std),\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Load datasets\n",
        "datasets_dict = {\n",
        "    'train': datasets.ImageFolder(train_dir, transform=data_transforms['train']),\n",
        "    'val': datasets.ImageFolder(validation_dir, transform=data_transforms['val']),\n",
        "}\n",
        "\n",
        "# Dataloaders\n",
        "batch_size = 32\n",
        "dataloaders = {\n",
        "    x: torch.utils.data.DataLoader(datasets_dict[x], batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "    for x in ['train', 'val']\n",
        "}\n",
        "\n",
        "# Dataset sizes and class names\n",
        "dataset_sizes = {x: len(datasets_dict[x]) for x in ['train', 'val']}\n",
        "class_names = datasets_dict['train'].classes\n",
        "print(f\"Classes: {class_names}\")\n",
        "\n",
        "# Step 4: Define Model\n",
        "# Load a pretrained ResNet18 model\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Freeze all layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the final fully connected layer for binary classification\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "model = model.to(device)\n",
        "\n",
        "# Step 5: Loss Function, Optimizer, and Learning Rate Scheduler\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "# Step 6: Training Function\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=5):\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best val Acc: {best_acc:.4f}')\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "# Step 7: Train the Model\n",
        "model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=25)\n",
        "\n",
        "# Step 8: Save the Model\n",
        "torch.save(model.state_dict(), 'cats_dogs_classifier.pth')\n",
        "\n",
        "# Step 9: Visualize Predictions\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images // 2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title(f'Predicted: {class_names[preds[j]]}')\n",
        "                img = inputs.cpu().data[j].numpy().transpose((1, 2, 0))\n",
        "                img = std * img + mean  # Denormalize\n",
        "                img = np.clip(img, 0, 1)\n",
        "                plt.imshow(img)\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "visualize_model(model)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7R64c0tV-zh"
      },
      "source": [
        "## Beginning to define the model (this is where you come in, I loaded the pretrained model for you)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}